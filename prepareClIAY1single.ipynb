{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dark_emulator at  /lustre/work/sunao.sugiyama/package/dark_emulator_public/dark_emulator/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dark_emulator_public import dark_emulator\n",
    "import os, sys, time, json\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict as od\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline as ius\n",
    "from scipy.interpolate import interp2d, interp1d\n",
    "from scipy.integrate import simps\n",
    "from tqdm import tqdm\n",
    "import hsc3x2pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation for Fisher\n",
    "Computation of $C(l)$ takes ~20 sec for each cosmology.\n",
    "So this notebook pre-compute $C(l)$ for cosmologies needed for Fisher analysis.\n",
    "\n",
    "Model parameters of 3x2pt analysis with single(double) source redshift bin are\n",
    "- comsology: 5\n",
    "- galaxy bias: 1x3\n",
    "- magnification bias: 1x3\n",
    "- photo-z: 1x1(2)\n",
    "- multiplicative bais: 1x1(2)\n",
    "\n",
    "13(15) parameters in total.\n",
    "\n",
    "$C(l)$s depend on cosmological parameters, galaxy bias and magnification bias, for which we need to compute $C(l)$.\n",
    "\n",
    "**Note** : Fisher analysis is doable even if the computational time for one model reaches ~20 sec. However, in the real analysis, ~20 sec is too much to run sampling code. \n",
    "I just want to know how people in cosmic shear, like Hikage-san and Hamana-san, or people in 3x2pt, like DES or KiDS, implement code of $C(l)$.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize cosmo_class\n",
      "Initialize pklin emulator\n",
      "initialize propagator emulator\n",
      "Initialize sigma_d emulator\n",
      "initialize cross-correlation emulator\n",
      "initialize auto-correlation emulator\n",
      "Initialize sigmaM emulator\n",
      "initialize xinl emulator\n"
     ]
    }
   ],
   "source": [
    "power_b1 = hsc3x2pt.power_b1_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Omega_s_HSC = 140"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of models to compute $C(l)$ to compute **single** source bin anlaysis\n",
    "0. fiducial = Planck cosmology + fiducial galaxy bias, magnification bais + 0 photo-z and multiplicative bias\n",
    "1. $\\omega_b h^2$ +\n",
    "2. $\\omega_c h^2$ +\n",
    "3. $\\Omega_{\\rm de}$ +\n",
    "4. $n_{\\rm s}$ +\n",
    "5. $\\ln 10^{10}A_{\\rm s}$ +\n",
    "6. $b_{\\rm 1,1}$ + \n",
    "7. $b_{\\rm 1,2}$ + \n",
    "8. $b_{\\rm 1,3}$ + \n",
    "9. $\\alpha_{\\rm mag,1}$ + \n",
    "10. $\\alpha_{\\rm mag,2}$ + \n",
    "11. $\\alpha_{\\rm mag,3}$ + \n",
    "12. $\\Delta z_{\\rm ph}$ +\n",
    "13. $\\Delta m$ + = easy. Just multiply $1+\\Delta m$ to fiducial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = 'precomputed_Cl/single_source_ClY1IA'\n",
    "\n",
    "def compute(params, dir_to_save, compute_lens_cross=False):\n",
    "    t0 = time.time()\n",
    "    ombh2, omch2, Ode, sigma8, ns, b11, b12, b13, a1, a2, a3, dzph, dm, A_IA, eta_IA = params\n",
    "    g_l1 = hsc3x2pt.galaxy_sample_lens_class(['lowz'  , 0.15, 0.30, b11, '40.36e-4 arcmin^-2', a1])\n",
    "    g_l2 = hsc3x2pt.galaxy_sample_lens_class(['cmass1', 0.47, 0.55, b12, '20.06e-4 arcmin^-2', a2])\n",
    "    g_l3 = hsc3x2pt.galaxy_sample_lens_class(['cmass2', 0.55, 0.70, b13, '30.12e-4 arcmin^-2', a3])\n",
    "    g_s12= hsc3x2pt.galaxy_sample_source_IA_class(['s12', 'sourcePzs_Y1/MLZs34.txt', dzph, dm, A_IA, eta_IA, 0.2, '6.6 arcmin^-2'])\n",
    "    pk2cl = hsc3x2pt.pk2cl_class(power_b1)\n",
    "    pk2cl.set_galaxy_sample(g_l1)\n",
    "    pk2cl.set_galaxy_sample(g_l2)\n",
    "    pk2cl.set_galaxy_sample(g_l3)\n",
    "    pk2cl.set_galaxy_sample(g_s12)\n",
    "    # set cosmo\n",
    "    cosmo_dict = dict(zip(['omega_b', 'omega_c', 'Omega_de', 'ln10p10As', 'n_s', 'w_de'], [ombh2, omch2, Ode, 3.094, ns, -1]))\n",
    "    pk2cl.set_cosmology_from_dict(cosmo_dict)\n",
    "    sigma8_temp = pk2cl.pk_class.get_sigma8()\n",
    "    ln10p10As = 3.094 + 2*np.log(sigma8/sigma8_temp)\n",
    "    print(f'ln10p10As={ln10p10As}')\n",
    "    cosmo_dict = dict(zip(['omega_b', 'omega_c', 'Omega_de', 'ln10p10As', 'n_s', 'w_de'], [ombh2, omch2, Ode, ln10p10As, ns, -1]))\n",
    "    pk2cl.set_cosmology_from_dict(cosmo_dict)\n",
    "    \n",
    "    pk2cl.init_pk()\n",
    "    pk2cl.set_Omega_s({'w':8300, 'gamma_t':Omega_s_HSC, 'xi':Omega_s_HSC}) # HSCY1\n",
    "\n",
    "    l = np.logspace(-2, 5, 1000)\n",
    "    with hsc3x2pt.Time():\n",
    "        pk2cl.compute_all_Cl(l, compute_lens_cross=compute_lens_cross)\n",
    "    pk2cl.dump_Cl_cache(f'{dirname}/{dir_to_save}', overwrite=True, silent=True)\n",
    "    t1 = time.time()\n",
    "    print(f'{t1-t0} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = 0.01\n",
    "file_param = od()\n",
    "\n",
    "def save_dparam(dparam, dir_to_save):\n",
    "    fname = os.path.join(dirname, 'file_param.json')\n",
    "    if os.path.exists(fname):\n",
    "        file_param = json.load(open(fname, 'r'), object_pairs_hook=od) \n",
    "    else:\n",
    "        file_param = od()\n",
    "    file_param[dir_to_save] = dparam\n",
    "    json.dump(file_param, open(fname, 'w'), indent=2)\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "def get_param(names, param_fiducial, absolute_dp, idx):\n",
    "    param = copy.deepcopy(param_fiducial)\n",
    "    if absolute_dp[idx]:\n",
    "        param[idx] = dp\n",
    "        dparam = dp\n",
    "    else:\n",
    "        param[idx] = param[idx]*(1+dp)\n",
    "        dparam = param[idx]*dp\n",
    "    name = names[idx]\n",
    "    return name, param, dparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln10p10As=3.097214912859019\n",
      ":26.444217681884766 sec\n",
      "26.85903263092041 sec\n"
     ]
    }
   ],
   "source": [
    "param_fiducial = [0.02225, 0.1198, 0.6844, 0.831, 0.9645, 1.78 , 2.10 , 2.28 , 2.259, 3.563, 3.729, 0.0 , 0.0 , 1.0  , 3.0]\n",
    "absolute_dp    = [False  , False , False , False, False , False, False, False, False, False, False, True, True, False, False]\n",
    "names = ['omega_b', 'omega_c', 'Omega_de', 'sigma8', 'ns', 'b1lowz', 'b1cmass1', 'b1cmass2', 'alphamaglowz', 'alphamagcmass1', 'alphamagcmass2', 'dzph', 'dm', 'A_IA', 'eta_IA']\n",
    "compute(param_fiducial, 'fiducial', compute_lens_cross=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Computing omega_b\n",
      "ln10p10As=3.1004231384103087\n",
      ":16.984068155288696 sec\n",
      "17.368055820465088 sec\n",
      ">>> Computing omega_c\n",
      "ln10p10As=3.082647998157684\n",
      ":17.157678842544556 sec\n",
      "17.54237675666809 sec\n",
      ">>> Computing Omega_de\n",
      "ln10p10As=3.092198150550478\n",
      ":16.967852115631104 sec\n",
      "17.356382131576538 sec\n",
      ">>> Computing sigma8\n",
      "ln10p10As=3.117115574565356\n",
      ":17.093859910964966 sec\n",
      "17.472084522247314 sec\n",
      ">>> Computing ns\n",
      "ln10p10As=3.0899386610164075\n",
      ":17.010557413101196 sec\n",
      "17.39804983139038 sec\n",
      ">>> Computing b1lowz\n",
      "ln10p10As=3.097214912859019\n",
      ":17.09132432937622 sec\n",
      "17.470704793930054 sec\n",
      ">>> Computing b1cmass1\n",
      "ln10p10As=3.097214912859019\n",
      ":17.08319664001465 sec\n",
      "17.47083616256714 sec\n",
      ">>> Computing b1cmass2\n",
      "ln10p10As=3.097214912859019\n",
      ":16.99283528327942 sec\n",
      "17.377151489257812 sec\n",
      ">>> Computing alphamaglowz\n",
      "ln10p10As=3.097214912859019\n",
      ":17.03222680091858 sec\n",
      "17.41188359260559 sec\n",
      ">>> Computing alphamagcmass1\n",
      "ln10p10As=3.097214912859019\n",
      ":17.062827825546265 sec\n",
      "17.44679617881775 sec\n",
      ">>> Computing alphamagcmass2\n",
      "ln10p10As=3.097214912859019\n",
      ":17.05655264854431 sec\n",
      "17.4414701461792 sec\n",
      ">>> Computing dzph\n",
      "ln10p10As=3.097214912859019\n",
      ":17.01132297515869 sec\n",
      "17.392611026763916 sec\n",
      ">>> Computing dm\n",
      "ln10p10As=3.097214912859019\n",
      ":17.017935752868652 sec\n",
      "17.401919841766357 sec\n",
      ">>> Computing A_IA\n",
      "ln10p10As=3.097214912859019\n",
      ":16.96911358833313 sec\n",
      "17.352766513824463 sec\n",
      ">>> Computing eta_IA\n",
      "ln10p10As=3.097214912859019\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(names)):\n",
    "    name, param, dparam = get_param(names, param_fiducial, absolute_dp, idx)\n",
    "    print(f'>>> Computing {name}')\n",
    "    compute(param, name)\n",
    "    save_dparam(dparam, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(dirname, 'param_fiducial.txt'), np.array(param_fiducial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Fisher analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov.shape = (66, 66), dim(data)=(66,)\n",
      "cov.shape = (17, 17), dim(data)=(17,)\n",
      "skip b1lowz because this is lens galaxy param, while probes does not include any lens related probe.\n",
      "skip b1cmass1 because this is lens galaxy param, while probes does not include any lens related probe.\n",
      "skip b1cmass2 because this is lens galaxy param, while probes does not include any lens related probe.\n",
      "skip alphamaglowz because this is lens galaxy param, while probes does not include any lens related probe.\n",
      "skip alphamagcmass1 because this is lens galaxy param, while probes does not include any lens related probe.\n",
      "skip alphamagcmass2 because this is lens galaxy param, while probes does not include any lens related probe.\n",
      "cov.shape = (83, 83), dim(data)=(83,)\n"
     ]
    }
   ],
   "source": [
    "fisher2x2pt = hsc3x2pt.getFisher(dirname, power_b1, probes=['w', 'gamma_t'], \n",
    "                                 label='2x2pt IA (Y1, 1bin)')\n",
    "fisher1x2pt = hsc3x2pt.getFisher(dirname, power_b1, probes=['xi+','xi-'], \n",
    "                                 label='Cosmic Shear IA (Y1, 1bin)')\n",
    "fisher3x2pt = hsc3x2pt.getFisher(dirname, power_b1,\n",
    "                                 label='3x2pt IA (Y1, 1bin)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FisherMats/single_source_ClY1IA/fisher3x2pt.cmp']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "dirname_fisher = os.path.join('FisherMats/', os.path.basename(dirname))\n",
    "if not os.path.exists(dirname_fisher):\n",
    "    os.mkdir(dirname_fisher)\n",
    "joblib.dump(fisher1x2pt, os.path.join(dirname_fisher, 'fisher1x2pt.cmp'), compress=True)\n",
    "joblib.dump(fisher2x2pt, os.path.join(dirname_fisher, 'fisher2x2pt.cmp'), compress=True)\n",
    "joblib.dump(fisher3x2pt, os.path.join(dirname_fisher, 'fisher3x2pt.cmp'), compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378.304856300354 sec\n"
     ]
    }
   ],
   "source": [
    "print(time.time()-t_start, 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
